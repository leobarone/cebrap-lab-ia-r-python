{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sumarização + Zero‑Shot (Hugging Face) para Corpus de Propostas Legislativas\n\n**Objetivo:** primeiro, gerar **sumários** curtos das propostas em `corpus.csv`; em seguida, aplicar **classificação Zero‑Shot** **sobre os sumários** para rótulos temáticos.\n\nEste notebook é voltado a **pesquisadoras(es) de ciências sociais** e traz **código fragmentado** com **comentários extensos**. Ao final, salvamos:\n\n- `corpus_summaries.csv` — com a coluna `summary`.\n- `corpus_sum_zero_shot.csv` — com `summary` + rótulo previsto e *scores* por rótulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Preparação do ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instale (uma vez) as bibliotecas. Em ambientes gerenciados, prefira instalar fora do notebook. Aqui ficam os comandos apenas como referência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# !pip install -U transformers torch pandas\n# Opcional: para modelos multilíngues menores, você pode testar mT5 (summarization via text2text)\n# !pip install -U sentencepiece\n# Observação: em máquinas sem GPU, o pipeline usará CPU automaticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Imports e detecção de dispositivo (CPU/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\nimport math\nimport pandas as pd\nfrom transformers import pipeline\n\ntry:\n    import torch\n    DEVICE = 0 if torch.cuda.is_available() else -1\nexcept Exception:\n    DEVICE = -1\n\nDEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Configurações: modelos, limites e rótulos candidatos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Modelos sugeridos**:\n\n- **Sumarização**: `facebook/bart-large-cnn` (inglês; funciona razoavelmente em PT para exemplos simples) — *pipeline* `summarization`.\n  - Alternativas multilíngues: `csebuetnlp/mT5_multilingual_XLSum` (via `text2text-generation`) ou variantes mT5/mBART afinadas.\n- **Zero‑Shot**: `facebook/bart-large-mnli` (NLI clássico). Para multilíngue, teste `joeddav/xlm-roberta-large-xnli`.\n\n**Limites práticos**:\n- Documentos longos podem exceder o limite do modelo. Abaixo usamos **truncagem simples** por tamanho de caracteres para fins didáticos.\n- Em produção, prefira **map‑reduce** (sumarizar partes → resumir os resumos) e controle de *prompt/decoding*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "SUM_MODEL = \"facebook/bart-large-cnn\"\nSUM_MAX_INPUT_CHARS = 3500\nSUM_MAX_NEW_TOKENS = 120\nSUM_MIN_NEW_TOKENS = 40\n\nZS_MODEL = \"facebook/bart-large-mnli\"\nCANDIDATE_LABELS = [\"judiciário\", \"cultura\", \"esporte\", \"economia\", \"direitos humanos\"]\nHYPOTHESIS_TEMPLATE = \"Este texto é sobre {}.\"\n\nSUM_BATCH = 4\nZS_BATCH  = 16\n\nSUM_MODEL, ZS_MODEL, CANDIDATE_LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Carregar o corpus (`corpus.csv`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O arquivo deve conter a coluna **`text`**. Outras colunas (ex.: `id`, `n_paginas`, `n_caracteres`) serão preservadas. Se o separador for diferente (`,`/`;`/`\\t`), usamos `sep=None` (detecção automática)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "CSV_PATH = \"corpus.csv\"\ndf = pd.read_csv(CSV_PATH, engine=\"python\", sep=None, on_bad_lines=\"skip\")\nassert \"text\" in df.columns, \"O CSV precisa ter a coluna 'text'.\"\ndf.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1) Esquema e normalização mínima do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\ndf[[\"id\",\"text\"]].head(3) if \"id\" in df.columns else df[[\"text\"]].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Instanciar o *pipeline* de sumarização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O `pipeline('summarization')` cuida de tokenização, modelo e pós‑processamento. Para inputs longos, aplicamos **truncagem por caracteres** (didático). Em produção, prefira **map‑reduce**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "summ = pipeline(\n    task=\"summarization\",\n    model=SUM_MODEL,\n    device=DEVICE\n)\nsumm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Sumarização — teste rápido com **um único texto**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "example_text = (\n    \"Dispõe sobre a inclusão de disposições no Código de Processo Penal para assegurar maior celeridade e \"\n    \"eficácia nas investigações criminais e promover a responsabilidade compartilhada na segurança pública.\"\n)\ninp = example_text[:SUM_MAX_INPUT_CHARS]\nsumm(example_text, max_new_tokens=SUM_MAX_NEW_TOKENS, min_new_tokens=SUM_MIN_NEW_TOKENS, do_sample=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Sumarização do corpus (em lotes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Função utilitária para **lotes** e geração da coluna `summary`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def batched(iterable, batch_size):\n    total = len(iterable)\n    for i in range(0, total, batch_size):\n        yield iterable[i:i+batch_size], i, min(i+batch_size, total), total\n\nsummaries = []\ntexts = df[\"text\"].tolist()\nprint(\"Gerando sumários…\")\nfor batch, i, j, total in batched(texts, SUM_BATCH):\n    clipped = [t[:SUM_MAX_INPUT_CHARS] for t in batch]\n    out = summ(\n        clipped,\n        max_new_tokens=SUM_MAX_NEW_TOKENS,\n        min_new_tokens=SUM_MIN_NEW_TOKENS,\n        do_sample=False\n    )\n    for o in out:\n        summaries.append(o[\"summary_text\"])  # chave padrão do pipeline\n    print(f\"  Lote {i+1}-{j} / {total}\", end=\"\\r\")\n\nprint(\"\\nConcluído.\")\nlen(summaries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1) Anexar `summary` ao DataFrame e salvar (`corpus_summaries.csv`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"summary\"] = summaries\ndf.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "SUM_OUT = \"corpus_summaries.csv\"\ndf.to_csv(SUM_OUT, index=False)\nSUM_OUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Classificação Zero‑Shot **sobre os sumários**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "clf = pipeline(\n    task=\"zero-shot-classification\",\n    model=ZS_MODEL,\n    device=DEVICE\n)\nclf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1) Rodar e coletar resultados (em lotes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pred_labels = []\npred_scores = []\nper_label_scores = {lab: [] for lab in CANDIDATE_LABELS}\n\nsumm_texts = df[\"summary\"].fillna(\"\").astype(str).tolist()\nprint(\"Rodando zero-shot sobre sumários…\")\nfor batch, i, j, total in batched(summ_texts, ZS_BATCH):\n    outputs = clf(\n        sequences=batch,\n        candidate_labels=CANDIDATE_LABELS,\n        hypothesis_template=HYPOTHESIS_TEMPLATE,\n        multi_label=False\n    )\n    if isinstance(outputs, dict):\n        outputs = [outputs]\n    for out in outputs:\n        best_label = out[\"labels\"][0]\n        best_score = float(out[\"scores\"][0])\n        pred_labels.append(best_label)\n        pred_scores.append(best_score)\n\n        score_map = {lab: None for lab in CANDIDATE_LABELS}\n        for lab, sc in zip(out[\"labels\"], out[\"scores\"]):\n            score_map[lab] = float(sc)\n        for lab in CANDIDATE_LABELS:\n            per_label_scores[lab].append(score_map.get(lab, None))\n\n    print(f\"  Lote {i+1}-{j} / {total}\", end=\"\\r\")\n\nprint(\"\\nConcluído.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2) Anexar previsões ao DataFrame e salvar (`corpus_sum_zero_shot.csv`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"pred_label\"] = pred_labels\ndf[\"pred_confidence\"] = pred_scores\nfor lab in CANDIDATE_LABELS:\n    df[f\"score_{lab}\"] = per_label_scores[lab]\n\ndf.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "OUT_PATH = \"corpus_sum_zero_shot.csv\"\ndf.to_csv(OUT_PATH, index=False)\nOUT_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Boas práticas e variações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Map‑reduce** para textos longos; **controle** de `max_new_tokens` e *decoding*.\n- **PT‑BR**: experimente mT5/mBART em PT; para Zero‑Shot multilíngue, use XLM‑R XNLI.\n- **Multi‑rótulo** com thresholds por categoria.\n- **Rastreabilidade**: salve versões dos modelos, parâmetros e datas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Por que estes modelos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Sumarização (Funcionamento):** ler e condensar; **Modelo:** seq2seq (BART/T5/mT5) com controle de comprimento.\n\n**Zero‑Shot (Funcionamento):** comparar sumário com rótulos em linguagem natural; **Modelo:** NLI (MNLI) que estima *entailment*.\n\n**Escolhas:** `facebook/bart-large-cnn` como baseline comum; `facebook/bart-large-mnli` como clássico para Zero‑Shot. Para PT‑BR/multilíngue, teste mT5/mBART para sumarização e XLM‑R‑XNLI para zero‑shot."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}