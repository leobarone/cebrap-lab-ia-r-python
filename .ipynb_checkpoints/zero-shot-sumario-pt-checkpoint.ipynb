{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumarização em **Português** + Zero‑Shot em Sumários (Hugging Face)\n",
    "\n",
    "**Objetivo:** gerar **sumários em português** para cada documento em `corpus.csv` (coluna `text`) usando um modelo mT5 multilíngue; em seguida, aplicar **classificação Zero‑Shot** **sobre os sumários**.\n",
    "\n",
    "**Saídas:**\n",
    "- `corpus_summaries_pt.csv` — adiciona `summary_pt` ao corpus.\n",
    "- `corpus_sum_zero_shot_pt.csv` — inclui `summary_pt` + rótulo previsto e *scores* por rótulo.\n",
    "\n",
    "> Inclui *map‑reduce por tokens* para contornar limites de sequência e *fallback* caso seu PyTorch seja < 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Ambiente e verificações rápidas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['TRANSFORMERS_NO_TORCHVISION'] = '1'\n",
    "import transformers\n",
    "print('transformers:', getattr(transformers, '__version__', None))\n",
    "try:\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n",
    "    TORCH_GE_26 = tuple(int(x) for x in torch.__version__.split('.')[:2]) >= (2,6)\n",
    "except Exception as e:\n",
    "    print('torch não importou:', e)\n",
    "    TORCH_GE_26 = False\n",
    "from transformers import pipeline\n",
    "print('Pipeline OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Configurações de modelos e rótulos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "SUM_MODEL_PT_PRIMARY = 'csebuetnlp/mT5_multilingual_XLSum'\n",
    "SUM_MODEL_PT_FALLBACK = 'google/mt5-small'\n",
    "ZS_MODEL = 'joeddav/xlm-roberta-large-xnli'\n",
    "CANDIDATE_LABELS = ['judiciário','cultura','esporte','economia','direitos humanos']\n",
    "HYPOTHESIS_TEMPLATE = 'Este texto é sobre {}.'\n",
    "SUM_MAX_INPUT_CHARS = 4500\n",
    "SUM_BATCH = 3\n",
    "ZS_BATCH = 12\n",
    "SUM_PART_MAX_NEW = 80; SUM_PART_MIN_NEW = 20\n",
    "SUM_FINAL_MAX_NEW = 120; SUM_FINAL_MIN_NEW = 40\n",
    "ALLOW_SUM_FALLBACK = True\n",
    "CANDIDATE_LABELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Carregar o corpus (`corpus.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CSV_PATH = 'corpus.csv'\n",
    "df = pd.read_csv(CSV_PATH, engine='python', sep=None, on_bad_lines='skip')\n",
    "assert 'text' in df.columns, \"O CSV precisa ter a coluna 'text'\"\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) *Pipeline* de sumarização (PT) com fallback"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "def init_summarizer(device=-1):\n",
    "    try:\n",
    "        summ = pipeline('text2text-generation', model=SUM_MODEL_PT_PRIMARY, device=device)\n",
    "        return summ, summ.tokenizer, False\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        if ('upgrade torch to at least v2.6' in msg.lower() or 'cve' in msg.lower()) and ALLOW_SUM_FALLBACK:\n",
    "            print('[AVISO] torch < 2.6 bloqueou o checkpoint. Usando fallback (qualidade menor):', SUM_MODEL_PT_FALLBACK)\n",
    "            summ = pipeline('text2text-generation', model=SUM_MODEL_PT_FALLBACK, device=device)\n",
    "            return summ, summ.tokenizer, True\n",
    "        raise\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "except Exception:\n",
    "    DEVICE = -1\n",
    "summ_pt, tok_pt, used_fallback = init_summarizer(DEVICE)\n",
    "print('Summarizer pronto. Fallback?', used_fallback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Utilitários: dividir por tokens e sumarização *map‑reduce*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def chunk_by_tokens(text: str, tokenizer, max_tokens: int = 480) -> List[str]:\n",
    "    toks = tokenizer(text, return_attention_mask=False, return_tensors=None, add_special_tokens=False)\n",
    "    ids = toks['input_ids']\n",
    "    chunks = []\n",
    "    for start in range(0, len(ids), max_tokens):\n",
    "        end = min(start + max_tokens, len(ids))\n",
    "        chunk_ids = ids[start:end]\n",
    "        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks\n",
    "def summarize_long_pt(text: str, summarizer, tokenizer,\n",
    "                      chunk_tokens=480,\n",
    "                      part_max_new=80, part_min_new=20,\n",
    "                      final_max_new=120, final_min_new=40,\n",
    "                      fallback_prompt=False) -> str:\n",
    "    def maybe_prompt(t):\n",
    "        return (f'Resuma em português, de forma objetiva: {t}') if fallback_prompt else t\n",
    "    parts = chunk_by_tokens(text, tokenizer, max_tokens=chunk_tokens)\n",
    "    if not parts:\n",
    "        return ''\n",
    "    part_out = summarizer([maybe_prompt(p) for p in parts], truncation=True,\n",
    "                          max_new_tokens=part_max_new, min_new_tokens=part_min_new, do_sample=False)\n",
    "    part_summaries = [o.get('generated_text', o.get('summary_text','')) for o in part_out]\n",
    "    joined = '\\n'.join(part_summaries)\n",
    "    final_out = summarizer(maybe_prompt(joined), truncation=True,\n",
    "                           max_new_tokens=final_max_new, min_new_tokens=final_min_new, do_sample=False)\n",
    "    return final_out[0].get('generated_text', final_out[0].get('summary_text',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Sumarizar o corpus (PT)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def batched(iterable, batch_size):\n",
    "    total = len(iterable)\n",
    "    for i in range(0, total, batch_size):\n",
    "        yield iterable[i:i+batch_size], i, min(i+batch_size, total), total\n",
    "summaries_pt = []\n",
    "texts = df['text'].tolist()\n",
    "print('Gerando sumários em português…')\n",
    "for batch, i, j, total in batched(texts, SUM_BATCH):\n",
    "    for t in batch:\n",
    "        t_clip = t[:SUM_MAX_INPUT_CHARS]\n",
    "        s = summarize_long_pt(t_clip, summ_pt, tok_pt, 480,\n",
    "                              SUM_PART_MAX_NEW, SUM_PART_MIN_NEW,\n",
    "                              SUM_FINAL_MAX_NEW, SUM_FINAL_MIN_NEW,\n",
    "                              used_fallback)\n",
    "        summaries_pt.append(s)\n",
    "    print(f'  Lote {i+1}-{j} / {total}', end='\\r')\n",
    "print('\\nConcluído.')\n",
    "len(summaries_pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Salvar sumários"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df['summary_pt'] = summaries_pt\n",
    "SUM_OUT = 'corpus_summaries_pt.csv'\n",
    "df.to_csv(SUM_OUT, index=False)\n",
    "SUM_OUT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Zero‑Shot sobre os sumários em PT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "clf = pipeline('zero-shot-classification', model=ZS_MODEL, device=DEVICE)\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1) Rodar e salvar previsões"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_labels, pred_scores = [], []\n",
    "per_label_scores = {lab: [] for lab in CANDIDATE_LABELS}\n",
    "summ_texts = df['summary_pt'].fillna('').astype(str).tolist()\n",
    "print('Rodando zero-shot…')\n",
    "for batch, i, j, total in batched(summ_texts, ZS_BATCH):\n",
    "    outputs = clf(sequences=batch, candidate_labels=CANDIDATE_LABELS,\n",
    "                  hypothesis_template=HYPOTHESIS_TEMPLATE, multi_label=False)\n",
    "    if isinstance(outputs, dict):\n",
    "        outputs = [outputs]\n",
    "    for out in outputs:\n",
    "        pred_labels.append(out['labels'][0])\n",
    "        pred_scores.append(float(out['scores'][0]))\n",
    "        smap = {lab: None for lab in CANDIDATE_LABELS}\n",
    "        for lab, sc in zip(out['labels'], out['scores']):\n",
    "            smap[lab] = float(sc)\n",
    "        for lab in CANDIDATE_LABELS:\n",
    "            per_label_scores[lab].append(smap.get(lab))\n",
    "    print(f'  Lote {i+1}-{j} / {total}', end='\\r')\n",
    "print('\\nConcluído.')\n",
    "df['pred_label'] = pred_labels\n",
    "df['pred_confidence'] = pred_scores\n",
    "for lab in CANDIDATE_LABELS:\n",
    "    df[f'score_{lab}'] = per_label_scores[lab]\n",
    "OUT_PATH = 'corpus_sum_zero_shot_pt.csv'\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "OUT_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Observações\n",
    "- Se você **não precisa** de visão, pode desinstalar `torchvision` e `torchaudio`.\n",
    "- Para melhor compatibilidade com checkpoints do HF, mantenha **`torch >= 2.6`**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}