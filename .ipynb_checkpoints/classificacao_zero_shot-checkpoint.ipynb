{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Classificação zero-shot (PT-BR) de Projetos de Lei\n\nNotebook gerado a partir do seu script, com cada etapa separada em células de código e títulos em células de texto."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0) Imports e configuração"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 0) Imports\n\nimport os\nos.environ[\"TRANSFORMERS_NO_TORCHVISION\"] = \"1\"\n\nfrom transformers import pipeline\n\nimport torch\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nprint(\"PyTorch:\", torch.__version__, \"| CUDA disponível?\", torch.cuda.is_available())\n\nimport math\nimport pandas as pd\nfrom tqdm.auto import tqdm"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Carregar o corpus"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 1) Carrega o corpus\ncsv_path = \"corpus.csv\"\ndf = pd.read_csv(csv_path, engine=\"python\", sep=None, on_bad_lines=\"skip\")\nassert {\"id\",\"text\"}.issubset(df.columns), \"O CSV precisa ter colunas 'id' e 'text'\""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Definir rótulos (ajuste à sua realidade)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 2) Defina os rótulos (ajuste à sua realidade)\ncandidate_labels = [\n    \"saúde\", \"educação\", \"segurança pública\", \"economia\", \"tributos\",\n    \"meio ambiente\", \"direitos humanos\", \"administração pública\",\n    \"trânsito e transporte\", \"trabalho e previdência\",\n    \"agropecuária\", \"tecnologia e proteção de dados\",\n    \"justiça e processo penal\", \"consumidor\", \"energia e mineração\",\n    \"habitação e urbanismo\", \"cultura e esporte\"\n]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Criar pipeline zero-shot multilíngue"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 3) Cria o pipeline de zero-shot multilíngue\nmodel_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\nclf = pipeline(\n    \"zero-shot-classification\",\n    model=model_name,\n    device_map=\"auto\",          # usa GPU se houver, senão CPU\n    truncation=True\n)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Utilitários (chunking e classificação do documento)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 4) Funções de utilidade\ndef chunk_text(txt, max_chars=1800):\n    \"\"\"Fatia textos longos em pedaços ~seguro para tokenização; evita truncamento.\"\"\"\n    txt = str(txt) if not isinstance(txt, str) else txt\n    if len(txt) <= max_chars:\n        return [txt]\n    chunks = []\n    start = 0\n    while start < len(txt):\n        end = min(start + max_chars, len(txt))\n        # tenta quebrar em espaço/pontuação para evitar quebra dura\n        if end < len(txt):\n            cut = txt.rfind(\" \", start, end)\n            if cut == -1 or cut - start < 0.6 * max_chars:\n                cut = txt.rfind(\".\", start, end)\n            end = cut if cut != -1 else end\n        chunks.append(txt[start:end].strip())\n        start = end\n    return [c for c in chunks if c]\n\ndef classify_doc(text, labels, multi_label=True, hypothesis_template=\"Este texto trata de {}.\"):\n    \"\"\"Classifica um doc potencialmente longo: roda por chunks e faz média dos scores.\"\"\"\n    chunks = chunk_text(text)\n    # acumula somando scores (logits já estão calibrados pelo pipeline → somar e normalizar pela média)\n    agg = {lab: 0.0 for lab in labels}\n    for ch in chunks:\n        out = clf(\n            ch,\n            candidate_labels=labels,\n            multi_label=multi_label,\n            hypothesis_template=hypothesis_template\n        )\n        # out['labels'] alinhado a out['scores']\n        for lab, sc in zip(out[\"labels\"], out[\"scores\"]):\n            agg[lab] += float(sc)\n    # média por número de chunks\n    n = len(chunks)\n    for k in agg:\n        agg[k] /= n\n    # ordena rótulos por score\n    ranked = sorted(agg.items(), key=lambda x: x[1], reverse=True)\n    top_label, top_score = ranked[0]\n    return agg, ranked, top_label, top_score"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Processar corpus e salvar resultados"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 5) Processa todo o corpus\nrecords = []\nfor _, row in tqdm(df.iterrows(), total=len(df)):\n    doc_id = row[\"id\"]\n    text = row[\"text\"]\n    scores, ranked, top_label, top_score = classify_doc(text, candidate_labels, multi_label=True)\n    rec = {\"id\": doc_id, \"top_label\": top_label, \"top_score\": round(top_score, 4)}\n    # adiciona probabilidades por rótulo\n    for lab in candidate_labels:\n        rec[f\"p_{lab}\"] = round(scores[lab], 4)\n    # também salva os 3 melhores para inspeção rápida\n    rec[\"top3\"] = \", \".join([f\"{lab}:{round(sc,3)}\" for lab, sc in ranked[:3]])\n    records.append(rec)\n\nout = pd.DataFrame(records)\nout_path = \"classificacao_zero_shot.csv\"\nout.to_csv(out_path, index=False)\nprint(f\"OK! Resultados salvos em {out_path}\")\nprint(out.head())"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}