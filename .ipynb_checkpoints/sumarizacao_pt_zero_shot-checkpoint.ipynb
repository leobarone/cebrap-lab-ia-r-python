{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sumarização em **Português** + Zero‑Shot em Sumários (Hugging Face)\n\n**Objetivo:** gerar **sumários em português** para cada documento em `corpus.csv` (coluna `text`) usando um modelo mT5 multilíngue; em seguida, aplicar **classificação Zero‑Shot** **sobre os sumários**.\n\n**Saídas:**\n- `corpus_summaries_pt.csv` — adiciona `summary_pt` ao corpus.\n- `corpus_sum_zero_shot_pt.csv` — inclui `summary_pt` + rótulo previsto e *scores* por rótulo.\n\n> Este notebook é didático: código fragmentado, comentários extensos e uma versão **robusta** de sumarização com *map‑reduce por tokens* para evitar limites de sequência."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Preparação do ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instale (uma vez) as bibliotecas. Em ambientes gerenciados, prefira instalar fora do notebook. Os comandos abaixo são apenas referência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# !pip install -U transformers torch pandas sentencepiece\n# Observação: em máquinas sem GPU, o pipeline usará CPU automaticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Imports e detecção de dispositivo (CPU/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\nimport pandas as pd\nfrom transformers import pipeline\n\ntry:\n    import torch\n    DEVICE = 0 if torch.cuda.is_available() else -1\nexcept Exception:\n    DEVICE = -1\n\nDEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Configurações: modelos PT e rótulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Sumarização em PT**: `csebuetnlp/mT5_multilingual_XLSum` (multilíngue ajustado para sumarização, funciona bem em português).\n\n**Zero‑Shot**: `joeddav/xlm-roberta-large-xnli` (XNLI multilíngue; lida bem com PT)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ---- Sumarização (Português)\nSUM_MODEL_PT = \"csebuetnlp/mT5_multilingual_XLSum\"\nSUM_MAX_INPUT_CHARS = 4500  # corte de segurança por caracteres (antes da tokenização)\nSUM_PART_MAX_NEW = 80       # tokens novos nos mini‑resumos\nSUM_PART_MIN_NEW = 20\nSUM_FINAL_MAX_NEW = 120     # tokens novos no meta‑resumo\nSUM_FINAL_MIN_NEW = 40\n\n# ---- Zero‑Shot (multilíngue/PT)\nZS_MODEL = \"joeddav/xlm-roberta-large-xnli\"\nCANDIDATE_LABELS = [\n    \"judiciário\", \"cultura\", \"esporte\", \"economia\", \"direitos humanos\"\n]\nHYPOTHESIS_TEMPLATE = \"Este texto é sobre {}.\"\n\n# ---- Batching\nSUM_BATCH = 3  # mT5 é mais pesado; mantenha pequeno em CPU\nZS_BATCH  = 12\n\nSUM_MODEL_PT, ZS_MODEL, CANDIDATE_LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Carregar o corpus (`corpus.csv`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "CSV_PATH = \"corpus.csv\"\ndf = pd.read_csv(CSV_PATH, engine=\"python\", sep=None, on_bad_lines=\"skip\")\nassert \"text\" in df.columns, \"O CSV precisa ter a coluna 'text'.\"\ndf[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\ndf.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Instanciar o *pipeline* de sumarização em português (mT5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O checkpoint mT5 é **text2text**; usamos `pipeline('text2text-generation')`. Vamos também criar utilitários para **map‑reduce por tokens**, evitando limites de sequência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "summ_pt = pipeline(\n    task=\"text2text-generation\",\n    model=SUM_MODEL_PT,\n    device=DEVICE\n)\nsumm_pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Utilitários: divisão por **tokens** e sumarização *map‑reduce* (PT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List\n\ndef chunk_by_tokens(text: str, tokenizer, max_tokens: int = 480) -> List[str]:\n    \"\"\"Divide o texto em blocos que, tokenizados, não passem de max_tokens.\n    Mantemos margem para *special tokens*.\"\"\"\n    toks = tokenizer(text, return_attention_mask=False, return_tensors=None, add_special_tokens=False)\n    ids = toks[\"input_ids\"]\n    chunks = []\n    for start in range(0, len(ids), max_tokens):\n        end = min(start + max_tokens, len(ids))\n        chunk_ids = ids[start:end]\n        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n        chunks.append(chunk_text)\n    return chunks\n\ndef summarize_long_pt(text: str, summarizer, tokenizer,\n                      chunk_tokens=480,\n                      part_max_new=80, part_min_new=20,\n                      final_max_new=120, final_min_new=40) -> str:\n    parts = chunk_by_tokens(text, tokenizer, max_tokens=chunk_tokens)\n    if not parts:\n        return \"\"\n    # 1) Resumir partes (PT)\n    part_out = summarizer(\n        parts,\n        truncation=True,\n        max_new_tokens=part_max_new,\n        min_new_tokens=part_min_new,\n        do_sample=False\n    )\n    part_summaries = [o.get(\"generated_text\", \"\") for o in part_out]\n    # 2) Meta‑resumo (PT)\n    joined = \"\\n\".join(part_summaries)\n    final_out = summarizer(\n        joined,\n        truncation=True,\n        max_new_tokens=final_max_new,\n        min_new_tokens=final_min_new,\n        do_sample=False\n    )\n    return final_out[0].get(\"generated_text\", \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Sumarizar o corpus em **português** (map‑reduce por tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def batched(iterable, batch_size):\n    total = len(iterable)\n    for i in range(0, total, batch_size):\n        yield iterable[i:i+batch_size], i, min(i+batch_size, total), total\n\nsummaries_pt = []\ntexts = df[\"text\"].tolist()\nprint(\"Gerando sumários em português…\")\nfor batch, i, j, total in batched(texts, SUM_BATCH):\n    for t in batch:\n        t_clip = t[:SUM_MAX_INPUT_CHARS]  # corte de segurança por caracteres\n        s = summarize_long_pt(\n            text=t_clip,\n            summarizer=summ_pt,\n            tokenizer=summ_pt.tokenizer,\n            chunk_tokens=480,\n            part_max_new=SUM_PART_MAX_NEW,\n            part_min_new=SUM_PART_MIN_NEW,\n            final_max_new=SUM_FINAL_MAX_NEW,\n            final_min_new=SUM_FINAL_MIN_NEW\n        )\n        summaries_pt.append(s)\n    print(f\"  Lote {i+1}-{j} / {total}\", end=\"\\r\")\n\nprint(\"\\nConcluído.\")\nlen(summaries_pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1) Salvar sumários PT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"summary_pt\"] = summaries_pt\nSUM_OUT = \"corpus_summaries_pt.csv\"\ndf.to_csv(SUM_OUT, index=False)\nSUM_OUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Zero‑Shot **sobre os sumários em PT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "clf = pipeline(\n    task=\"zero-shot-classification\",\n    model=ZS_MODEL,\n    device=DEVICE\n)\nclf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1) Rodar e coletar previsões (em lotes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pred_labels = []\npred_scores = []\nper_label_scores = {lab: [] for lab in CANDIDATE_LABELS}\n\nsumm_texts = df[\"summary_pt\"].fillna(\"\").astype(str).tolist()\nprint(\"Rodando zero-shot sobre sumários PT…\")\nfor batch, i, j, total in batched(summ_texts, ZS_BATCH):\n    outputs = clf(\n        sequences=batch,\n        candidate_labels=CANDIDATE_LABELS,\n        hypothesis_template=HYPOTHESIS_TEMPLATE,\n        multi_label=False\n    )\n    if isinstance(outputs, dict):\n        outputs = [outputs]\n    for out in outputs:\n        best_label = out[\"labels\"][0]\n        best_score = float(out[\"scores\"][0])\n        pred_labels.append(best_label)\n        pred_scores.append(best_score)\n\n        score_map = {lab: None for lab in CANDIDATE_LABELS}\n        for lab, sc in zip(out[\"labels\"], out[\"scores\"]):\n            score_map[lab] = float(sc)\n        for lab in CANDIDATE_LABELS:\n            per_label_scores[lab].append(score_map.get(lab, None))\n\n    print(f\"  Lote {i+1}-{j} / {total}\", end=\"\\r\")\n\nprint(\"\\nConcluído.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2) Salvar previsões"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"pred_label\"] = pred_labels\ndf[\"pred_confidence\"] = pred_scores\nfor lab in CANDIDATE_LABELS:\n    df[f\"score_{lab}\"] = per_label_scores[lab]\n\nOUT_PATH = \"corpus_sum_zero_shot_pt.csv\"\ndf.to_csv(OUT_PATH, index=False)\nOUT_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Observações e escolhas de modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Sumarização PT (Funcionamento):** o mT5 lê o texto e produz um resumo conciso em português; **Modelo:** *seq2seq* com vocabulário subword multilíngue, afinado no dataset XLSum.\n\n**Zero‑Shot (Funcionamento):** com rótulos em linguagem natural, o XLM‑R XNLI estima se o sumário *entails* cada rótulo; **Modelo:** encoder multilíngue ajustado em XNLI. Para tarefas puramente em PT, também é possível usar BART‑MNLI com bom desempenho prático."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}